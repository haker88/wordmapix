{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "import html\n",
    "import pandas as pd\n",
    "import googletrans\n",
    "from google.cloud import translate_v2\n",
    "import six\n",
    "import numpy as np\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "import distance    \n",
    "from unidecode import unidecode\n",
    "from google.cloud import translate_v2 as translate\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from shapely.geometry import LineString, MultiLineString\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'key.json'\n",
    "translate_client = translate.Client()\n",
    "langs = googletrans.LANGUAGES\n",
    "langs['rw']='Kinyarwanda'\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(langs)\n",
    "def translate_text_with_model(target, text, model=\"nmt\"):\n",
    "    if isinstance(text, six.binary_type):\n",
    "        text = text.decode(\"utf-8\")\n",
    "    result = translate_client.translate(text, target_language=target, model=model)\n",
    "    res = unidecode(result[\"translatedText\"])\n",
    "    res = html.unescape(res)\n",
    "    res = res.replace(\"@\", 'å')\n",
    "    res = res.replace(\"~\", 'i')\n",
    "    res = res.lower()    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatedf(phrase):\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    wordslist = \"\"\n",
    "    listw = []\n",
    "    for l in langs:\n",
    "        translate_text = translate_text_with_model(l,phrase)\n",
    "        translate_text = str(translate_text)\n",
    "        translate_text = translate_text.replace(\" \", \"\")\n",
    "        wordslist = wordslist +\" \"+ translate_text\n",
    "        listw.append(translate_text)\n",
    "\n",
    "    df = pd.DataFrame(listw)\n",
    "    df['clusterID'] =\"empty\"\n",
    "    df['LN'] = langs\n",
    "    df['clusterID'] = pd.Series(dtype=int)\n",
    "    eng = df[(df['LN'] == 'en')]\n",
    "    eng = eng.loc[eng.index.repeat(28)]\n",
    "    eng.iloc[0,2] = 'au'\n",
    "    eng.iloc[1,2] = 'zn'\n",
    "    eng.iloc[2,2] = 'ca'\n",
    "    eng.iloc[3,2] = 'us'\n",
    "    eng.iloc[4,2] = 'gy'\n",
    "    eng.iloc[5,2] = 'zw'\n",
    "    eng.iloc[6,2] = 'zm'\n",
    "    eng.iloc[7,2] = 'bs'\n",
    "    eng.iloc[8,2] = 'sc'\n",
    "    eng.iloc[9,2] = 'sh'\n",
    "    eng.iloc[10,2] = 'ng'\n",
    "    eng.iloc[11,2] = 'na'\n",
    "    eng.iloc[12,2] = 'mw'\n",
    "    eng.iloc[13,2] = 'mu'\n",
    "    eng.iloc[14,2] = 'lr'\n",
    "    eng.iloc[15,2] = 'ke'\n",
    "    eng.iloc[16,2] = 'cm'\n",
    "    eng.iloc[17,2] = 'bw'\n",
    "    eng.iloc[18,2] = 'za'\n",
    "    eng.iloc[19,2] = 'ss'\n",
    "    eng.iloc[20,2] = 'nz'\n",
    "    eng.iloc[21,2] = 'jm'\n",
    "    eng.iloc[22,2] = 'pg'\n",
    "    eng.iloc[24,2] = 'bz'\n",
    "    eng.iloc[25,2] = 'pr'\n",
    "    eng.iloc[26,2] = 'sl'\n",
    "    df.loc[df.LN =='he','LN'] = 'il'\n",
    "    df.loc[df.LN =='bs','LN'] = 'ba'\n",
    "    df.loc[df.LN =='sv','LN'] = 'se'\n",
    "    df.loc[df.LN =='en','LN'] = 'gb'\n",
    "    df.loc[df.LN =='hi','LN'] = 'in'\n",
    "    df.loc[df.LN =='ga','LN'] = 'ie'\n",
    "    df.loc[df.LN =='sw','LN'] = 'tz'\n",
    "    df.loc[df.LN =='be','LN'] = 'by'\n",
    "    df.loc[df.LN =='uk','LN'] = 'ua'\n",
    "    df.loc[df.LN =='si','LN'] = 'lk'\n",
    "    df.loc[df.LN =='pa','LN'] = 'pk'\n",
    "    df.loc[df.LN =='kk','LN'] = 'kz'\n",
    "    df.loc[df.LN =='da','LN'] = 'dk'\n",
    "    df.loc[df.LN =='cs','LN'] = 'cz'\n",
    "    df.loc[df.LN =='el','LN'] = 'gr'\n",
    "    df.loc[df.LN =='sr','LN'] = 'rs'\n",
    "    df.loc[df.LN =='tk','LN'] = 'tm'\n",
    "    df.loc[df.LN =='ka','LN'] = 'ge'\n",
    "    df.loc[df.LN =='tg','LN'] = 'tj'\n",
    "    df.loc[df.LN =='ky','LN'] = 'kg'\n",
    "    df.loc[df.LN =='bn','LN'] = 'bd'\n",
    "    df.loc[df.LN =='bu','LN'] = 'my'\n",
    "    df.loc[df.LN =='vn','LN'] = 'vi'\n",
    "    df.loc[df.LN =='ja','LN'] = 'jp'\n",
    "    df.loc[df.LN =='ko','LN'] = 'kp'\n",
    "    df.loc[df.LN =='tl','LN'] = 'ph'\n",
    "    df.loc[df.LN =='ti','LN'] = 'er'\n",
    "    df.loc[df.LN =='et','LN'] = 'ee'\n",
    "    df.loc[df.LN =='vi','LN'] = 'vn'\n",
    "    df.loc[df.LN =='km','LN'] = 'kh'\n",
    "    df.loc[df.LN =='am','LN'] = 'et'\n",
    "    df.loc[df.LN =='my','LN'] = 'mm'\n",
    "    df.loc[df.LN =='ma','LN'] = 'my'\n",
    "    df.loc[df.LN =='ne','LN'] = 'np'\n",
    "    df.loc[df.LN =='dz','LN'] = 'bt'\n",
    "    df.loc[df.LN =='st','LN'] = 'ls'\n",
    "    df.loc[df.LN =='zu','LN'] = 'sz'\n",
    "    df.loc[df.LN =='sl','LN'] = 'si'\n",
    "    df.loc[df.LN =='sq','LN'] = 'al'\n",
    "    df.loc[df.LN =='hy','LN'] = 'am'\n",
    "    df.loc[df.LN =='ms','LN'] = 'my'\n",
    "    df.loc[df.LN =='gl','LN'] = 'da'\n",
    "\n",
    "    spanish = ['bo','co','mx','ar','cl','cr','cu', 'dm', 'ec','sv', 'gq', 'gt', 'hn', 'ni', 'pa','py', 'uy', 'pe', 've']\n",
    "    spa = df[(df['LN'] == 'es')]\n",
    "    spa = spa.loc[spa.index.repeat(len(spanish))]\n",
    "    for i,s in enumerate(spanish):\n",
    "        spa.iloc[i,2] = s\n",
    "    port = ['br','ao','mz','pt','gw','tl','mo','cv']\n",
    "    po = df[(df['LN'] == 'pt')]\n",
    "    po = po.loc[po.index.repeat(len(port))]\n",
    "    for i,s in enumerate(port):\n",
    "        po.iloc[i,2] = s\n",
    "\n",
    "    port = ['er','ir','eg','dz','bh','ig','iq','jo','kw','ly','ma','om','ps','qa','sa','so','sy','tn','ae','ye','do']\n",
    "    ara = df[(df['LN'] == 'ar')]\n",
    "    ara = ara.loc[ara.index.repeat(len(port))]\n",
    "    for i,s in enumerate(port):\n",
    "        ara.iloc[i,2] = s \n",
    "\n",
    "    port = ['gn','bf','bj','bi','cf','td','cg','cd','dj','ci','dj', 'ga', 'gh', 'gm','ne', 're','tg']\n",
    "    fra = df[(df['LN'] == 'af')]\n",
    "    fra = fra.loc[fra.index.repeat(len(port))]\n",
    "    for i,s in enumerate(port):\n",
    "        fra.iloc[i,2] = s    \n",
    "\n",
    "    port = ['at','be','ch','li']\n",
    "    ger = df[(df['LN'] == 'de')]\n",
    "    ger = ger.loc[ger.index.repeat(len(port))]\n",
    "    for i,s in enumerate(port):\n",
    "        ger.iloc[i,2] = s   \n",
    "\n",
    "    port = ['sr','aw']\n",
    "    dut = df[(df['LN'] == 'nl')]\n",
    "    dut = dut.loc[dut.index.repeat(len(port))]\n",
    "    for i,s in enumerate(port):\n",
    "        dut.iloc[i,2] = s   \n",
    "\n",
    "    port = ['tm']\n",
    "    tur = df[(df['LN'] == 'tr')]\n",
    "    tur = tur.loc[tur.index.repeat(len(port))]\n",
    "    for i,s in enumerate(port):\n",
    "        tur.iloc[i,2] = s   \n",
    "\n",
    "    port = ['md']\n",
    "    rom = df[(df['LN'] == 'ro')]\n",
    "    rom = rom.loc[rom.index.repeat(len(port))]\n",
    "    for i,s in enumerate(port):\n",
    "        rom.iloc[i,2] = s   \n",
    "\n",
    "    port = ['kr']\n",
    "    kor = df[(df['LN'] == 'kp')]\n",
    "    kor = kor.loc[kor.index.repeat(len(port))]\n",
    "    for i,s in enumerate(port):\n",
    "        kor.iloc[i,2] = s   \n",
    "\n",
    "    port = ['me']\n",
    "    mon = df[(df['LN'] == 'ba')]\n",
    "    mon = mon.loc[mon.index.repeat(len(port))]\n",
    "    for i,s in enumerate(port):\n",
    "        mon.iloc[i,2] = s         \n",
    "\n",
    "\n",
    "    frames = [df, eng, spa, po, ara, fra, ger, dut, tur, rom, kor, mon] \n",
    "    df = pd.concat(frames)\n",
    "\n",
    "    words = wordslist.split(\" \") #Replace this line\n",
    "    words = np.asarray(words) #So that indexing with a list will work\n",
    "    lev_similarity = -1*np.array([[distance.levenshtein(w1,w2) for w1 in words] for w2 in words])\n",
    "\n",
    "    affprop = AffinityPropagation(affinity=\"precomputed\", damping=0.85)\n",
    "    affprop.fit(lev_similarity)\n",
    "    clusterNo = 0\n",
    "    for cluster_id in np.unique(affprop.labels_):\n",
    "        exemplar = words[affprop.cluster_centers_indices_[cluster_id]]\n",
    "        cluster = np.unique(words[np.nonzero(affprop.labels_==cluster_id)])\n",
    "        for i in cluster:\n",
    "            for index, row in df.iterrows():\n",
    "                if i ==row[0]:\n",
    "                    #df.at[index, 'clusterID'] = 2\n",
    "                    df.at[index, 'clusterID'] = clusterNo\n",
    "        cluster_str = \", \".join(cluster)\n",
    "        #print(\" - *%s:* %s\" % (exemplar, cluster_str))\n",
    "        clusterNo = clusterNo + 1\n",
    "    df = df.drop(df[df['clusterID']==\"empty\"].index)\n",
    "    df.loc[df.LN =='zh-cn','LN'] = 'cn'\n",
    "    df.loc[df.LN =='zh-tw','LN'] = 'tw'\n",
    "    codes_df = pd.read_csv(\"codes.csv\")\n",
    "    for i, col in enumerate(codes_df.columns):\n",
    "        codes_df.iloc[:, i] = codes_df.iloc[:, i].str.replace('\"', '')\n",
    "    codes_df['Alpha-2 code'].str.lower()\n",
    "    codes_df['Alpha-2 code'] = codes_df['Alpha-2 code'].apply(lambda x:x.lower())\n",
    "    codes_df.rename(columns={'Alpha-2 code':'LN'}, inplace=True)\n",
    "    codes_df.rename(columns={'Latitude (average)':'Lat'}, inplace=True)\n",
    "    codes_df.rename(columns={'Longitude (average)':'Lon'}, inplace=True)\n",
    "    df[\"LN\"] = df[\"LN\"].astype('string')\n",
    "    codes_df[\"LN\"] = codes_df[\"LN\"].astype('string')\n",
    "    codes_df['LN'] = codes_df['LN'].str.replace(\" \",\"\")\n",
    "    #show.loc[show.LN =='zh-cn','Country'] = 'China'\n",
    "    #codes_df.loc[codes_df.LN =='zh-cn','LN'] = 'cn'\n",
    "\n",
    "    show = pd.merge(df, codes_df, on =[\"LN\"], how='left')\n",
    "    show['Alpha-3 code'] = show['Alpha-3 code'].str.replace(\" \",\"\")\n",
    "    show.dropna()\n",
    "    #show = show.drop_duplicates(subset='Country', keep=\"last\")\n",
    "    show.loc[show.LN =='zu','Country'] = 'South Africa'\n",
    "    show.loc[show.LN =='fa','Country'] = 'Iraq'\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    show = show.drop(show[(show.Country =='Somalia') & (show.index > 100)].index)\n",
    "    show = show.drop(show[(show.Country =='Argentina') & (show.index < 100)].index)\n",
    "    show = show.drop(show[(show.Country =='Canada') & (show.index < 100)].index)\n",
    "    show = show.drop(show[(show.Country =='Colombia') & (show.index < 100)].index)\n",
    "    show = show.drop(show[(show.Country =='Portugal') & (show.index < 100)].index)\n",
    "    show = show.drop(show[(show.Country =='Bolivia')].index)\n",
    "    show = show.drop(show[(show.Country =='Venezuela')].index)\n",
    "    show = show.drop(show[(show.Country ==\"Côte d'Ivoire\")].index)\n",
    "    show = show.drop(show[(show.Country ==\"Congo\")].index)\n",
    "    return show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "                           \n",
    "def mapa(show, phrase):\n",
    "    %matplotlib inline\n",
    "    color = ['mediumturquoise' , 'lightskyblue', 'green' , 'lightcoral' , 'lightgreen' , 'lemonchiffon' , 'darkorange' , 'lightblue', 'wheat' , 'darkgrey', 'tan', 'lightgrey', 'orchid', 'deepskyblue', 'cornflowerblue', 'gold','lime', 'cyan','lightsalmon', 'mediumslateblue','teal', 'chartreuse', 'dodgerblue', 'paleturquoise','slateblue','coral','palevioletred','mediumslateblue', 'blue','olive','thistle','crimson','gray','olivedrab','darkkhaki']\n",
    "    shp = shpreader.natural_earth(resolution='50m',category='cultural',\n",
    "                                     name='admin_0_countries')\n",
    "    reader = shpreader.Reader(shp)   \n",
    "    fig = plt.figure(figsize=(60, 30))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.Robinson())\n",
    "    for index, row in show.iterrows():\n",
    "            latx = row['Lat']\n",
    "            lonx = row['Lon']\n",
    "            length = len(str(row[0]))\n",
    "            if row['Country'] == 'Greenland':\n",
    "                ax.text(float(lonx)-length/2.9-2,float(latx)-5, row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Canada':\n",
    "                ax.text(float(lonx)-length/2.9-10,float(latx)-2, row[0], fontsize=30,fontweight='bold',transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Belize':\n",
    "                ax.text(float(lonx)-length/2.9+2,float(latx), row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Israel':\n",
    "                ax.text(float(lonx)-length/2.9+2.5,float(latx), row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Bahrain':\n",
    "                ax.text(float(lonx)-length/2.9,float(latx)+1, row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Panama':\n",
    "                ax.text(float(lonx)-length/2.9,float(latx)-2.5, row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Honduras':\n",
    "                ax.text(float(lonx)-length/2.9+2.5,float(latx)-1, row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Belize':\n",
    "                ax.text(float(lonx)-length/2.9+1,float(latx), row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Gambia':\n",
    "                ax.text(float(lonx)-length/2.9-1,float(latx), row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Dominican Republic':\n",
    "                ax.text(float(lonx)-length/2.9,float(latx)+1.5, row[0], fontsize=30,fontweight='bold',transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'El Salvador':\n",
    "                ax.text(float(lonx)-length/2.9-2.5,float(latx)-1, row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Suriname':\n",
    "                ax.text(float(lonx)-length/2.9+1,float(latx), row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Armenia':\n",
    "                ax.text(float(lonx)-length/2.9-1,float(latx)-1, row[0], fontsize=30,fontweight='bold',transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Azerbaijan':\n",
    "                ax.text(float(lonx)-length/2.9+1,float(latx)+1, row[0], fontsize=30,fontweight='bold',transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Lithuania':\n",
    "                ax.text(float(lonx)-length/2.9,float(latx)-1, row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Ireland':\n",
    "                ax.text(float(lonx)-length/2.9-3.5,float(latx)-0.5, row[0], fontsize=30,fontweight='bold',transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Portugal':\n",
    "                ax.text(float(lonx)-length/2.9-6.5,float(latx)-0.5, row[0], fontsize=30,fontweight='bold',transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Iceland':\n",
    "                ax.text(float(lonx)-length/2.9,float(latx)-2.5, row[0], fontsize=30,fontweight='bold',transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Nicaragua':\n",
    "                ax.text(float(lonx)-length/2.9+2.5,float(latx)-1, row[0], fontsize=30,fontweight='bold',transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Puerto Rico':\n",
    "                ax.text(float(lonx)-length/2.9,float(latx)+1, row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'New Zealand':\n",
    "                ax.text(float(lonx)-length/2.9-4,float(latx)+2, row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Haiti':\n",
    "                ax.text(float(lonx)-length/2.9-3,float(latx), row[0], fontsize=30,fontweight='bold',transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Netherlands':\n",
    "                ax.text(float(lonx)-length/2.9,float(latx)-3, row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Ghana':\n",
    "                ax.text(float(lonx)-length/2.9,float(latx)-4.5, row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Liberia':\n",
    "                ax.text(float(lonx)-length/2.9,float(latx)-4.5, row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Guinea-Bissau':\n",
    "                ax.text(float(lonx)-length/2.9-3,float(latx)-3, row[0], fontsize=30,fontweight='bold',transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Jamaica':\n",
    "                ax.text(float(lonx)-length/2.9-3,float(latx), row[0], fontsize=30,fontweight='bold',transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Switzerland':\n",
    "                ax.text(float(lonx)-length/2.9-3.9,float(latx)+2, row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Moldavia':\n",
    "                ax.text(float(lonx)-length/2.9+3,float(latx), row[0], fontsize=30,fontweight='bold',transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Jordan':\n",
    "                ax.text(float(lonx)-length/2.9+3.5,float(latx)-1.5, row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Syrian Arab Republic':\n",
    "                ax.text(float(lonx)-length/2.9-3.5,float(latx), row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Burundi':\n",
    "                ax.text(float(lonx)-length/2.9,float(latx)-1, row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Italy':\n",
    "                ax.text(float(lonx)-length/2.9-4,float(latx), row[0], fontsize=30,fontweight='bold',transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Lebanon':\n",
    "                ax.text(float(lonx)-length/2.9+2,float(latx)+1, row[0], fontsize=30,fontweight='bold',transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Greece':\n",
    "                ax.text(float(lonx)-length/2.9,float(latx)-4, row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Albania':\n",
    "                ax.text(float(lonx)-length/2.9,float(latx)-2, row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Slovenia':\n",
    "                ax.text(float(lonx)-length/2.9-4,float(latx), row[0], fontsize=30,fontweight='bold',transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Senegal':\n",
    "                ax.text(float(lonx)-length/2.9,float(latx)+2, row[0], fontsize=30,fontweight='bold',transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Kosovo':\n",
    "                ax.text(float(lonx)-length/2.9+1,float(latx)-1, row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Philippines':\n",
    "                ax.text(float(lonx)-length/2.9-3.5,float(latx)-1, row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Mauritius':\n",
    "                ax.text(float(lonx)-length/2.9+2.5,float(latx), row[0], fontsize=30,fontweight='bold',transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Cyprus':\n",
    "                ax.text(float(lonx)-length/2.9-2,float(latx)-2, row[0], fontsize=30,fontweight='bold',transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Macedonia':\n",
    "                ax.text(float(lonx)-length/2.9+2,float(latx)-3, row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Italy':\n",
    "                ax.text(float(lonx)-length/2.9+2,float(latx)-3.2, row[0], fontsize=30,fontweight='bold',transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Austria':\n",
    "                ax.text(float(lonx)-length/2.9+2,float(latx)-0.5, row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Germany':\n",
    "                ax.text(float(lonx)-length/2.9+2,float(latx), row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Dennmark':\n",
    "                ax.text(float(lonx)-length/2.9-3,float(latx), row[0], fontsize=30,fontweight='bold',transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Bosnia and Herzegovina':\n",
    "                ax.text(float(lonx)-length/2.9-1,float(latx), row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Norway':\n",
    "                ax.text(float(lonx)-length/2.9-2.5,float(latx)-1, row[0], fontsize=30,fontweight='bold',transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Somalia':\n",
    "                ax.text(float(lonx)-length/2.9+2,float(latx)-4, row[0], fontsize=30,fontweight='bold',transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Sri Lanka':\n",
    "                ax.text(float(lonx)-length/2.9+3.5,float(latx)-1, row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Lesotho':\n",
    "                ax.text(float(lonx)-length/2.9+1.5,float(latx)-2.5, row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'France':\n",
    "                ax.text(float(lonx)-length/2.9-2,float(latx), row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Ivory Coast':\n",
    "                ax.text(float(lonx)-length/2.9,float(latx)-2, row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Tanzania':\n",
    "                ax.text(float(lonx)-length/2.9-2,float(latx)+4, row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Ethiopia':\n",
    "                ax.text(float(lonx)-length/2.9,float(latx)-3, row[0],fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Botswana':\n",
    "                ax.text(float(lonx)-length/2.9,float(latx)-2.5, row[0], fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Madagascar':\n",
    "                ax.text(float(lonx)-length/2.9,float(latx)+2, row[0], fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Uruguay':\n",
    "                ax.text(float(lonx)-length/2.9,float(latx)+2, row[0], fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Nigeria':\n",
    "                ax.text(float(lonx)-length/2.9,float(latx)+2.5, row[0], fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Bulgaria':\n",
    "                ax.text(float(lonx)-length/2.9,float(latx)-3, row[0], fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            elif row['Country'] == 'Namibia':\n",
    "                ax.text(float(lonx)-length/2.9-2,float(latx)+3.5, row[0], fontsize=30,fontweight='bold', transform=ccrs.Geodetic())\n",
    "            else:\n",
    "                ax.text(float(lonx)-length/1.5,float(latx), row[0], fontsize=30,fontweight='bold',transform=ccrs.Geodetic())\n",
    "     \n",
    "    \n",
    "    ax.add_feature(cfeature.BORDERS.with_scale('50m'))\n",
    "    ax.set_extent([-120,165, -40, 65])\n",
    "    ax.stock_img()\n",
    "    ax.coastlines()    \n",
    "    for index, row in show.iterrows():\n",
    "        for n in reader.records():\n",
    "            if n.attributes['ADM0_A3'] == row['Alpha-3 code']:\n",
    "                try:                    \n",
    "                    ax.add_geometries([n.geometry], ccrs.PlateCarree(), facecolor=str(color[int(row['clusterID'])]), \n",
    "                    alpha = 1.00, linewidth =0.15, edgecolor = \"black\")\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    pass\n",
    "            else:\n",
    "                if n.attributes['ISO_A3'] == row['Alpha-3 code']:\n",
    "                    try:                    \n",
    "                        ax.add_geometries([n.geometry], ccrs.PlateCarree(), facecolor=str(color[int(row['clusterID'])]), \n",
    "                        alpha = 1.00, linewidth =0.15, edgecolor = \"black\")\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        pass\n",
    "                else:\n",
    "                    if n.attributes['ISO_A2'] == row['Alpha-3 code']:\n",
    "                        try:                    \n",
    "                            ax.add_geometries([n.geometry], ccrs.Mollweide(), facecolor=str(color[int(row['clusterID'])]), \n",
    "                            alpha = 1.00, linewidth =0.1, edgecolor = \"black\")\n",
    "                        except Exception as e:\n",
    "                            print(e)\n",
    "                            pass\n",
    "                    \n",
    "                pass\n",
    "    ax.text(-49,-38, 'Generated with #wordmapix \\n (coloring based on ethymology)',color='gold',fontsize=39,fontweight='bold',transform=ccrs.Geodetic())\n",
    "    plt.savefig('Count/' + str(phrase) + '.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = [\"python\", \"computer\", \"programmer\", \"algorithm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for p in phrases:\n",
    "    try:\n",
    "        #p = p[3:]\n",
    "        mapa(generatedf(p), p)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
